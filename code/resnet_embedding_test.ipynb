{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.colors import ColorsCorpusReader\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from utils.torch_color_describer import ContextualColorDescriber, create_example_dataset\n",
    "import utils.utils\n",
    "from utils.utils import UNK_SYMBOL, START_SYMBOL, END_SYMBOL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatch\n",
    "import numpy as np\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding\n",
    ")\n",
    "\n",
    "from experiment.vision import ConvolutionalColorEncoder\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetTokenizer, XLNetModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,    \n",
    ")\n",
    "\n",
    "import utils.model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.current_device()\n",
    "# torch.cuda.device(0)\n",
    "# torch.cuda.device_count()\n",
    "# torch.cuda.get_device_name()\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.utils.fix_random_seeds()\n",
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\"\n",
    ")\n",
    "corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")\n",
    "examples = list(corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAKE_OFF_COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"cs224u-colors-bakeoff-data.csv\"\n",
    ")\n",
    "bake_off_corpus = ColorsCorpusReader(\n",
    "    BAKE_OFF_COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")\n",
    "bake_off_examples = list(bake_off_corpus.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawcols, texts = zip(*[[ex.colors, ex.contents] for ex in examples[:10]])\n",
    "raw_colors_train, raw_colors_test, texts_train, texts_test = train_test_split(rawcols, texts)\n",
    "\n",
    "def create_data(tokenizer, include_position=False,include_conv_embeddings=False):\n",
    "    tokens_train = [\n",
    "        mu.tokenize_colour_description(text, tokenizer) for text in texts_train\n",
    "    ]  \n",
    "    return tokens_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/yanjiang/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "color_encoder = ConvolutionalColorEncoder(True)\n",
    "colors_train = [color_encoder.encode_color_context(colors) for colors in raw_colors_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 566]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colors_train[0]), colors_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_data():    \n",
    "    return zip(*[[ex.colors, ex.contents] for ex in bake_off_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trained_model, tokenizer, color_seqs_test, texts_test):\n",
    "    tok_seqs = [mu.tokenize_colour_description(text, tokenizer) for text in texts_test]\n",
    "    col_seqs = [color_encoder.encode_color_context(colors) for colors in color_seqs_test]\n",
    "    return trained_model.evaluate(col_seqs, tok_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 ms, sys: 845 µs, total: 2.97 ms\n",
      "Wall time: 2.17 ms\n"
     ]
    }
   ],
   "source": [
    "%time  tokens_train = create_data(bert_tokenizer)\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 ms, sys: 1.03 ms, total: 3.67 ms\n",
      "Wall time: 2.74 ms\n"
     ]
    }
   ],
   "source": [
    "%time bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding\n",
    ")\n",
    "from experiment.vision import ConvolutionalColorEncoder\n",
    "\n",
    "bert_model = BaselineDescriber(\n",
    "    vocab=bert_vocab,\n",
    "    embedding=bert_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.3114489316940308"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 309 ms, sys: 32.8 ms, total: 342 ms\n",
      "Wall time: 419 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = bert_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Evaluate on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.3333333333333333, 'corpus_bleu': 0.05000000000000001}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(bert_model, bert_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Evaluate on bakeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(bert_model, bert_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = create_data(xlnet_tokenizer)\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 ms, sys: 1.23 ms, total: 4.4 ms\n",
      "Wall time: 3.28 ms\n"
     ]
    }
   ],
   "source": [
    "%time xlnet_embeddings, xlnet_vocab = mu.extract_input_embeddings(texts_test, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_model = BaselineDescriber(\n",
    "    vocab=xlnet_vocab,\n",
    "    embedding=xlnet_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.3800020217895508"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 228 ms, sys: 20 ms, total: 248 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = xlnet_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.3333333333333333, 'corpus_bleu': 0.36787944117144233}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(xlnet_model, xlnet_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Evaluate on bakeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(xlnet_model, xlnet_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = create_data(roberta_tokenizer)\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 ms, sys: 797 µs, total: 3.61 ms\n",
      "Wall time: 3.11 ms\n"
     ]
    }
   ],
   "source": [
    "%time roberta_embeddings, roberta_vocab = mu.extract_input_embeddings(texts_test, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = BaselineDescriber(\n",
    "    vocab=roberta_vocab,\n",
    "    embedding=roberta_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 1.5666316747665405"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 345 ms, sys: 32.8 ms, total: 378 ms\n",
      "Wall time: 408 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = roberta_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.0, 'corpus_bleu': 0.05000000000000001}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(roberta_model, roberta_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(roberta_model, roberta_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
