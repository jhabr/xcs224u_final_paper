{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__authors__ = \"Anton Gochev, Jaro Habr, Yan Jiang, Samuel Kahn\"\n",
    "__version__ = \"XCS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colours with static embeddings\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Dataset](#Dataset)\n",
    "    1. [Filtered Corpus](#Filtered-Corpus)\n",
    "    1. [Bake-Off Corpus](#Bake-Off-Corpus)\n",
    "1. [Baseline-System](#Baseline-System)\n",
    "1. [Experiments](#Experiments)\n",
    "  1. [BERT Embeddings](#BERT-Embeddings)\n",
    "  2. [XLNet Embeddings](#XLNet-Embeddings)\n",
    "  3. [RoBERTa Embeddings](#RoBERTa-Embeddings)\n",
    "  4. [ELECTRA Embeddings](#ELECTRA-Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook explores the performance of the basemodel with using different pre-trained static embeddings extracted from transformers such as BERT, XLNet, RoBERTa, ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.colors import ColorsCorpusReader\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from utils.torch_color_describer import ContextualColorDescriber, create_example_dataset\n",
    "import utils.utils\n",
    "from utils.utils import UNK_SYMBOL, START_SYMBOL, END_SYMBOL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatch\n",
    "import numpy as np\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding,\n",
    "    ConvolutionalColorEncoder\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetTokenizer, XLNetModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,    \n",
    ")\n",
    "\n",
    "import utils.model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exploration of the dataset counts the examples for different classes and plots the words distribition in order to see any data imbalance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered corpus is the full dataset used in assignment 4. The following code looks at the composition of the dataset, the number of example in each condition as well as the word count used in the color descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_examples = mu.extract_colour_examples(examples, from_word_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_examples = [example for example in examples if example.condition == \"close\"]\n",
    "split_examples = [example for example in examples if example.condition == \"split\"]\n",
    "far_examples = [example for example in examples if example.condition == \"far\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close: 15519\n",
      "split: 15693\n",
      "far: 15782\n"
     ]
    }
   ],
   "source": [
    "print(f\"close: {len(close_examples)}\")\n",
    "print(f\"split: {len(split_examples)}\")\n",
    "print(f\"far: {len(far_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the datasets (training and bake-off) in more details refer to [colors_in_context.ipynb](colors_in_context.ipynb). The notebook shows the distribution of the colours examples among the different splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake-Off Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code analyses the bake-off dataset. We will look at the number of examples for each of the conditions as well as the word count used to described the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAKE_OFF_COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"cs224u-colors-bakeoff-data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_corpus = ColorsCorpusReader(\n",
    "    BAKE_OFF_COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_examples = list(bake_off_corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "emb_path = os.path.join(\n",
    "    \"data\", \"colors\", \"resnet18_color_embeddings.pickle\"\n",
    ")\n",
    "file = open(emb_path,'rb')\n",
    "resnet_emb = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13890"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resnet_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline-System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline system is based on assignment 4 and we use different token embeddings and sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding,\n",
    "    ConvolutionalColorEncoder\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline system development - dev dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tiny dataset is used for baseline model development and fast testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_data():\n",
    "    dev_color_seqs, dev_word_seqs, dev_vocab = create_example_dataset(\n",
    "        group_size=50,\n",
    "        vec_dim=2\n",
    "    )\n",
    "\n",
    "    dev_colors_train, dev_colors_test, dev_words_train, dev_words_test = \\\n",
    "        train_test_split(dev_color_seqs, dev_word_seqs)\n",
    "    \n",
    "    return dev_vocab, dev_colors_train, dev_words_train, dev_colors_test, dev_words_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_vocab, dev_colors_train, dev_tokens_train, dev_colors_test, dev_texts_test = \\\n",
    "    create_dev_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full color context dataset is used for final baseline model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(tokenizer, include_position=False,include_conv_embeddings=False):\n",
    "    if include_conv_embeddings==False:\n",
    "        rawcols, texts = zip(*[[ex.colors, ex.contents] for ex in examples])\n",
    "    \n",
    "    raw_colors_train, raw_colors_test, texts_train, texts_test = \\\n",
    "        train_test_split(rawcols, texts)\n",
    "    \n",
    "    raw_colors_train = raw_colors_train\n",
    "    texts_train = texts_train\n",
    "\n",
    "    tokens_train = [\n",
    "        mu.tokenize_colour_description(text, tokenizer) for text in texts_train\n",
    "    ]\n",
    "    colors_train = [\n",
    "        color_encoder.encode_colors_from_convnet(colors) for colors in raw_colors_train\n",
    "    ]\n",
    "\n",
    "    return colors_train, tokens_train, raw_colors_test, texts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_data():    \n",
    "    return zip(*[[ex.colors, ex.contents] for ex in bake_off_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the experiments:\n",
    "\n",
    "| Model | Protocol | Training Results | Bake-off Results |\n",
    "| --- | --- | --- | --- |\n",
    "| BERT 'bert-base-cased' | Stopping after epoch 54. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 115.87914156913757 CPU times: user 2h 4min 43s, sys: 1h 1min 36s, total: 3h 6min 19s Wall time: 1h 3min 47s | {'listener_accuracy': 0.8282407013362839, 'corpus_bleu': 0.4614753491619744} | {'listener_accuracy': 0.9034958148695224, 'corpus_bleu': 0.6637981882180088} |\n",
    "| XLNet 'xlnet-base-cased' | Stopping after epoch 55. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 117.36168694496155 CPU times: user 2h 18min 38s, sys: 1h 7min 4s, total: 3h 25min 43s Wall time: 1h 9min 34s | {'listener_accuracy': 0.8243254745084688, 'corpus_bleu': 0.4290345340732608} | {'listener_accuracy': 0.9034958148695224, 'corpus_bleu': 0.6462354138567806} |\n",
    "| RoBERTa 'roberta-base' | Stopping after epoch 71. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 88.95393252372742 CPU times: user 2h 26min 29s, sys: 1h 11min 9s, total: 3h 37min 38s Wall time: 1h 10min 30s | {'listener_accuracy': 0.8160694527193804, 'corpus_bleu': 0.43914107019568926} | {'listener_accuracy': 0.8936484490398818, 'corpus_bleu': 0.6365891729377956} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | Stopping after epoch 55. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 112.70061588287354 CPU times: user 1h 18min 13s, sys: 33min 6s, total: 1h 51min 20s Wall time: 37min 34s | {'listener_accuracy': 0.8459443356881436, 'corpus_bleu': 0.4808836633817978} | {'listener_accuracy': 0.914327917282127, 'corpus_bleu': 0.6813010156866868} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trained_model, tokenizer, color_seqs_test, texts_test):\n",
    "    tok_seqs = [mu.tokenize_colour_description(text, tokenizer) for text in texts_test]\n",
    "    col_seqs = [color_encoder.encode_colors_from_convnet(colors) for colors in color_seqs_test]\n",
    "\n",
    "    return trained_model.evaluate(col_seqs, tok_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/samuelkahn/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 16min 18s, sys: 17min 58s, total: 3h 34min 17s\n",
      "Wall time: 2h 42min 33s\n"
     ]
    }
   ],
   "source": [
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding,\n",
    "    ConvolutionalColorEncoder\n",
    ")\n",
    "color_encoder = ConvolutionalColorEncoder(\"resnet18\",True)\n",
    "%time  colors_train, tokens_train, raw_colors_test, texts_test = create_data(bert_tokenizer)\n",
    "\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 36.8 ms, total: 2.83 s\n",
      "Wall time: 2.84 s\n"
     ]
    }
   ],
   "source": [
    "%time bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 566])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time bert_positional_embeddings, bert_positional_vocab = \\\n",
    "#    mu.extract_positional_embeddings(texts_test, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Baseline model using BERT pretrained embeddings and vocab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder,\n",
    "    BaselineEmbedding, BaselineDescriber, GloVeEmbedding,\n",
    "    ConvolutionalColorEncoder\n",
    ")\n",
    "baseline_model = BaselineDescriber(\n",
    "    bert_vocab,\n",
    "    embedding=bert_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelkahn/Desktop/Stanford Grad Courses/cs224u/xcs224u_final_paper/code/utils/torch_color_describer.py:699: RuntimeWarning: divide by zero encountered in power\n",
      "  perp = [np.prod(s)**(-1/len(s)) for s in scores]\n",
      "Finished epoch 80 of 1000; error is 78.556766748428347"
     ]
    }
   ],
   "source": [
    "%time _ = baseline_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(baseline_model, bert_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.3825701624815362, 'corpus_bleu': 0.5236180769568916}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, bert_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLNet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_train, tokens_train, raw_colors_test, texts_test = create_data(xlnet_tokenizer)\n",
    "\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 41.3 ms, total: 3.39 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%time xlnet_embeddings, xlnet_vocab = mu.extract_input_embeddings(texts_test, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time bert_positional_embeddings, bert_positional_vocab = \\\n",
    "#    mu.extract_positional_embeddings(texts_test, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Baseline model using XLNet pretrained embeddings and vocab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineDescriber(\n",
    "    xlnet_vocab,\n",
    "    embedding=xlnet_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 55. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 117.36168694496155"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 18min 38s, sys: 1h 7min 4s, total: 3h 25min 43s\n",
      "Wall time: 1h 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%time _ = baseline_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.8243254745084688, 'corpus_bleu': 0.4290345340732608}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, xlnet_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.9034958148695224, 'corpus_bleu': 0.6462354138567806}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, xlnet_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_train, tokens_train, raw_colors_test, texts_test = create_data(roberta_tokenizer)\n",
    "\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 35.4 ms, total: 2.36 s\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%time roberta_embeddings, roberta_vocab = mu.extract_input_embeddings(texts_test, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time bert_positional_embeddings, bert_positional_vocab = \\\n",
    "#    mu.extract_positional_embeddings(texts_test, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Baseline model using RoBERTa pretrained embeddings and vocab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineDescriber(\n",
    "    roberta_vocab,\n",
    "    embedding=roberta_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 71. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 88.95393252372742"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 26min 29s, sys: 1h 11min 9s, total: 3h 37min 38s\n",
      "Wall time: 1h 10min 30s\n"
     ]
    }
   ],
   "source": [
    "%time _ = baseline_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.8160694527193804, 'corpus_bleu': 0.43914107019568926}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, roberta_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.8936484490398818, 'corpus_bleu': 0.6365891729377956}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, roberta_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELECTRA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "electra_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_train, tokens_train, raw_colors_test, texts_test = create_data(electra_tokenizer)\n",
    "\n",
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.66 s, sys: 7.9 ms, total: 2.67 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%time electra_embeddings, electra_vocab = mu.extract_input_embeddings(texts_test, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time bert_positional_embeddings, bert_positional_vocab = \\\n",
    "#    mu.extract_positional_embeddings(texts_test, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Baseline model using ELECTRA pretrained embeddings and vocab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineDescriber(\n",
    "    electra_vocab,\n",
    "    embedding=electra_embeddings,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 55. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 112.70061588287354"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 18min 13s, sys: 33min 6s, total: 1h 51min 20s\n",
      "Wall time: 37min 34s\n"
     ]
    }
   ],
   "source": [
    "%time _ = baseline_model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.8459443356881436, 'corpus_bleu': 0.4808836633817978}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, electra_tokenizer, raw_colors_test, texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listener_accuracy': 0.914327917282127, 'corpus_bleu': 0.6813010156866868}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, electra_tokenizer, b_raw_colors_test, b_texts_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
