{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__authors__ = \"Anton Gochev, Jaro Habr, Yan Jiang, Samuel Kahn\"\n",
    "__version__ = \"XCS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colours with static embeddings\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Dataset](#Dataset)\n",
    "    1. [Filtered Corpus](#Filtered-Corpus)\n",
    "    1. [Bake-Off Corpus](#Bake-Off-Corpus)\n",
    "1. [Baseline-System](#Baseline-System)\n",
    "1. [Experiments](#Experiments)\n",
    "  1. [BERT Embeddings](#BERT-Embeddings)\n",
    "  2. [XLNet Embeddings](#XLNet-Embeddings)\n",
    "  3. [RoBERTa Embeddings](#RoBERTa-Embeddings)\n",
    "  4. [ELECTRA Embeddings](#ELECTRA-Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook explores the performance of the basemodel with using different pre-trained static embeddings extracted from transformers such as BERT, XLNet, RoBERTa, ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.colors import ColorsCorpusReader\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from utils.torch_color_describer import ContextualColorDescriber, create_example_dataset\n",
    "import utils.utils as utils\n",
    "from utils.utils import UNK_SYMBOL, START_SYMBOL, END_SYMBOL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatch\n",
    "import numpy as np\n",
    "from baseline.model import (\n",
    "    BaselineTokenizer, BaselineColorEncoder, BaselineDescriber,\n",
    "    BaselineEmbedding, BaselineLSTMDescriber, GloVeEmbedding\n",
    ")\n",
    "from experiment.vision import ConvolutionalColorEncoder\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetTokenizer, XLNetModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,    \n",
    ")\n",
    "\n",
    "import utils.model_utils as mu\n",
    "import experiment.helper as eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exploration of the dataset counts the examples for different classes and plots the words distribition in order to see any data imbalance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered corpus is the full dataset used in assignment 4. The following code looks at the composition of the dataset, the number of example in each condition as well as the word count used in the color descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_examples = mu.extract_colour_examples(examples, from_word_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_examples = [example for example in examples if example.condition == \"close\"]\n",
    "split_examples = [example for example in examples if example.condition == \"split\"]\n",
    "far_examples = [example for example in examples if example.condition == \"far\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"close: {len(close_examples)}\")\n",
    "print(f\"split: {len(split_examples)}\")\n",
    "print(f\"far: {len(far_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the datasets (training and bake-off) in more details refer to [colors_in_context.ipynb](colors_in_context.ipynb). The notebook shows the distribution of the colours examples among the different splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake-Off Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code analyses the bake-off dataset. We will look at the number of examples for each of the conditions as well as the word count used to described the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAKE_OFF_COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"cs224u-colors-bakeoff-data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_corpus = ColorsCorpusReader(\n",
    "    BAKE_OFF_COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_examples = list(bake_off_corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "emb_path = os.path.join(\n",
    "    \"data\", \"colors\", \"resnet18_color_embeddings.pickle\"\n",
    ")\n",
    "file = open(emb_path,'rb')\n",
    "resnet_emb = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resnet_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline-System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline system is based on assignment 4 and we use different token embeddings and sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full color context dataset is used for final baseline model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawcols, texts = zip(*[[ex.colors, ex.contents] for ex in examples]) \n",
    "raw_colors_test_bo, texts_test_bo = zip(*[[ex.colors, ex.contents] for ex in bake_off_examples])\n",
    "\n",
    "raw_colors_train, raw_colors_test, texts_train, texts_test = \\\n",
    "        train_test_split(rawcols, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the experiments:\n",
    "\n",
    "| Model | Embeddings | Unit | h-params | Protocol | Training Results | Bake-off Results |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| BERT 'bert-base-cased' | ResNet18 + static | LSTM | default | Stopping after epoch 16. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 186.72212171554565 CPU times: user 51min 9s, sys: 21min 52s, total: 1h 13min 1s Wall time: 23min 55s | {'listener_accuracy': 0.3704996169886799, 'corpus_bleu': 0.4271658095590124} | {'listener_accuracy': 0.34711964549483015, 'corpus_bleu': 0.6166938495719256} |\n",
    "| BERT 'bert-base-cased' | ResNet18+Fourier + static | LSTM | default | Stopping after epoch 112. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 46.370091795921326 CPU times: user 6h 7min 3s, sys: 2h 36min 50s, total: 8h 43min 53s Wall time: 2h 53min 23s | {'listener_accuracy': 0.8209209294408035, 'corpus_bleu': 0.5904509830096333} | {'listener_accuracy': 0.9148202855736091, 'corpus_bleu': 0.7719649525541963} |\n",
    "| BERT 'bert-base-cased' | ResNet18+Fourier + static | LSTM | hid_dim=100 | Stopping after epoch 89. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 72.01054859161377 CPU times: user 5h 32min 19s, sys: 2h 8min 14s, total: 7h 40min 33s Wall time: 2h 47min 38s | {'listener_accuracy': 0.8190484296535875, 'corpus_bleu': 0.6143887490272109} | {'listener_accuracy': 0.8956179222058099, 'corpus_bleu': 0.7866291971865217} |\n",
    "| XLNet 'xlnet-base-cased' | ResNet18 + static | LSTM | default | Stopping after epoch 145. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 23.32861888408661 CPU times: user 8h 17min 22s, sys: 3h 23min 31s, total: 11h 40min 53s Wall time: 3h 46min 43s | {'listener_accuracy': 0.7549578687547877, 'corpus_bleu': 0.5648871242223105} | {'listener_accuracy': 0.8670605612998523, 'corpus_bleu': 0.7533564516719005} |\n",
    "| XLNet 'xlnet-base-cased' | ResNet18+Fourier + static | LSTM | default | Stopping after epoch 125. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 33.39379119873047 CPU times: user 7h 32min 8s, sys: 3h 6min 32s, total: 10h 38min 40s Wall time: 3h 28min 54s | {'listener_accuracy': 0.835645586858456, 'corpus_bleu': 0.5903786021680395} | {'listener_accuracy': 0.9113737075332349, 'corpus_bleu': 0.766034610276092} |\n",
    "| XLNet 'xlnet-base-cased' | ResNet18+Fourier + static | LSTM | hid_dim=100 | Stopping after epoch 76. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 89.37767934799194 CPU times: user 5h 32min 12s, sys: 2h 1min 52s, total: 7h 34min 4s Wall time: 2h 42min 29s | {'listener_accuracy': 0.8366669503787556, 'corpus_bleu': 0.581864699762294} | {'listener_accuracy': 0.9162973904480551, 'corpus_bleu': 0.7633163869123465} |\n",
    "| XLNet 'xlnet-base-cased' | ResNet18+Fourier + static | LSTM | hid_dim=250 | Stopping after epoch 56. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 115.53824925422668 CPU times: user 6h 38min 43s, sys: 1h 55min 55s, total: 8h 34min 38s Wall time: 3h 48min 39s | {'listener_accuracy': 0.6549493573921185, 'corpus_bleu': 0.2996265804208502} | {'listener_accuracy': 0.7311669128508124, 'corpus_bleu': 0.38023324553545096} |\n",
    "| XLNet 'xlnet-base-cased' (2) | ResNet18+Fourier + static | LSTM | hid_dim=250 | Stopping after epoch 50. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 127.68089389801025 CPU times: user 4h 43min 49s, sys: 1h 25min 23s, total: 6h 9min 12s Wall time: 2h 33min 41s | {'listener_accuracy': 0.8478168354753596, 'corpus_bleu': 0.5908243462277566} | {'listener_accuracy': 0.9148202855736091, 'corpus_bleu': 0.770364787937182} |\n",
    "| XLNet 'xlnet-base-cased' | ResNet18+Fourier + static | GRU | hid_dim=250 | Stopping after epoch 33. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 148.86750602722168 CPU times: user 3h 22min 40s, sys: 1h 1min 45s, total: 4h 24min 25s Wall time: 1h 53min 35s 39s | {'listener_accuracy': 0.6495020852838539, 'corpus_bleu': 0.29153560410619433} | {'listener_accuracy': 0.7257508616445101, 'corpus_bleu': 0.3740184682732033} |\n",
    "| XLNet 'xlnet-base-cased' (2) | ResNet18+Fourier + static | GRU | hid_dim=250 | Stopping after epoch 40. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 143.11642217636108 CPU times: user 3h 26min 43s, sys: 1h 4min 33s, total: 4h 31min 16s Wall time: 1h 50min 59s | {'listener_accuracy': 0.8321559281640991, 'corpus_bleu': 0.5825406845918764} | {'listener_accuracy': 0.7257508616445101, 'corpus_bleu': 0.3740184682732033} |\n",
    "| XLNet 'xlnet-base-cased' (3) | ResNet18+Fourier + static | GRU | hid_dim=250 | Stopping after epoch 51. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 127.30778098106384 CPU times: user 5h 21min 10s, sys: 1h 36min 17s, total: 6h 57min 27s Wall time: 2h 55min 45s | {'listener_accuracy': 0.8382841092858967, 'corpus_bleu': 0.5808065691051519} | {'listener_accuracy': 0.914327917282127, 'corpus_bleu': 0.7633533127675665} |\n",
    "| RoBERTa 'roberta-base' | ResNet18 + static | LSTM | default | Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 197.75724983215332 CPU times: user 52min 7s, sys: 19min 12s, total: 1h 11min 20s Wall time: 22min 11s | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "| RoBERTa 'roberta-base' | ResNet18+Fourier + static | LSTM | default | Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 201.13099479675293 CPU times: user 50min 9s, sys: 19min 13s, total: 1h 9min 22s Wall time: 21min 49s | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "| RoBERTa 'roberta-base' | ResNet18+Fourier + static | LSTM | hid_dim=100 | Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 196.342670917511 CPU times: user 1h 38s, sys: 20min 40s, total: 1h 21min 18s Wall time: 28min 6s | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} | {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | ResNet18 + static | LSTM | default | Stopping after epoch 200. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 12.498226076364517 CPU times: user 9h 58min 7s, sys: 3h 51min 46s, total: 13h 49min 54s Wall time: 4h 28min 38s | {'listener_accuracy': 0.8018554770618777, 'corpus_bleu': 0.5976330421393174} | {'listener_accuracy': 0.8936484490398818, 'corpus_bleu': 0.7839809145958113} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | ResNet18+Fourier + static | LSTM | default | Stopping after epoch 90. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 70.57668948173523 CPU times: user 4h 9min 47s, sys: 1h 40min 13s, total: 5h 50min Wall time: 1h 54min 18s | {'listener_accuracy': 0.8173461571197549, 'corpus_bleu': 0.6020019877608638} | {'listener_accuracy': 0.913343180699163, 'corpus_bleu': 0.7838522381057177} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | ResNet18+Fourier + static | LSTM | hid_dim=100 | Stopping after epoch 101. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 55.01819384098053 CPU times: user 6h 42min 17s, sys: 2h 18min 46s, total: 9h 1min 3s Wall time: 3h 14min 16s | {'listener_accuracy': 0.8438164950208529, 'corpus_bleu': 0.6099872860729817} | {'listener_accuracy': 0.9192516001969473, 'corpus_bleu': 0.7889350641465928} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | ResNet18+Fourier + static | LSTM | hid_dim=250 | Stopping after epoch 63. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 108.05819869041443 CPU times: user 6h 51min 1s, sys: 1h 52min 51s, total: 8h 43min 53s Wall time: 3h 45min 36s | {'listener_accuracy': 0.8496893352625755, 'corpus_bleu': 0.6152868875583275} | {'listener_accuracy': 0.9256523879862137, 'corpus_bleu': 0.7888655244301115} |\n",
    "| ELECTRA 'google/electra-small-discriminator' | ResNet18+Fourier + static | GRU | hid_dim=250 | Stopping after epoch 50. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 127.47516798973083 CPU times: user 5h 2min 18s, sys: 1h 25min 8s, total: 6h 27min 27s Wall time: 2h 42min 58s | {'listener_accuracy': 0.8374329730189803, 'corpus_bleu': 0.59792027562232} | {'listener_accuracy': 0.9148202855736091, 'corpus_bleu': 0.7844196479990682} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_encoder = ConvolutionalColorEncoder(True)\n",
    "%time colors_train, colors_test, colors_bo = \\\n",
    "    eh.create_colours_sets(color_encoder, raw_colors_train, raw_colors_test, raw_colors_test_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'train': colors_train, 'test': colors_test, 'bo': colors_bo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [50, 100, 150, 250]\n",
    "start_index = 7000\n",
    "end_index = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tokens_train, tokens_test, tokens_bo = \\\n",
    "    eh.create_tokens_sets(bert_tokenizer, texts_train, texts_test, texts_test_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_train, bert_model, bert_tokenizer, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiment with different hidden_dim size***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - BERT LSTM - static embeddings + ResNet+Fourier |\n",
    "| ------- |\n",
    "| Stopping after epoch 44. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 46.76516532897949 <br /> train 50 - {'listener_accuracy': 0.45654949357392116, 'corpus_bleu': 0.3822134017057766} <br /> bake-off 50 - {'listener_accuracy': 0.42146725750861647, 'corpus_bleu': 0.5439987449504363} |\n",
    "| Stopping after epoch 53. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 46.292728900909424 <br /> train 100 - {'listener_accuracy': 0.5274491446080517, 'corpus_bleu': 0.5350260003935228} <br /> bake-off 100 - {'listener_accuracy': 0.5701624815361891, 'corpus_bleu': 0.7108937241938815} |\n",
    "| Stopping after epoch 94. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 41.2493839263916 <br /> train 150 - {'listener_accuracy': 0.5913694782534684, 'corpus_bleu': 0.5246605959686265} <br /> bake-off 150 - {'listener_accuracy': 0.6814377154111275, 'corpus_bleu': 0.701929740281104} |\n",
    "| Stopping after epoch 62. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 43.86564564704895 <br /> train 250 - {'listener_accuracy': 0.597242318495191, 'corpus_bleu': 0.5090204246106848} <br /> bake-off 250 - {'listener_accuracy': 0.6578040374199902, 'corpus_bleu': 0.6742907898833734} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - BERT GRU - static embeddings + ResNet+Fourier |\n",
    "| ------- |\n",
    "| Stopping after epoch 53. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 43.16489589214325 <br /> train 50 - {'listener_accuracy': 0.45374074389309726, 'corpus_bleu': 0.5557992772981372} <br /> bake-off 50 - {'listener_accuracy': 0.48695224027572626, 'corpus_bleu': 0.7114784693608719} |\n",
    "| Stopping after epoch 50. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 45.62858486175537 <br /> train 100 - {'listener_accuracy': 0.530172780662184, 'corpus_bleu': 0.5187928224826821} <br /> bake-off 100 - {'listener_accuracy': 0.5839487936976858, 'corpus_bleu': 0.6876888605354385} |\n",
    "| Stopping after epoch 55. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 44.40023684501648 <br /> train 150 - {'listener_accuracy': 0.6003915226827815, 'corpus_bleu': 0.1633409451091387} <br /> bake-off 150 - {'listener_accuracy': 0.6681437715411127, 'corpus_bleu': 0.14443461637230007} |\n",
    "| Stopping after epoch 93. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 41.163474321365356 <br /> train 250 - {'listener_accuracy': 0.6660992424887224, 'corpus_bleu': 0.5453195319279439} <br /> bake-off 250 - {'listener_accuracy': 0.7154111275233875, 'corpus_bleu': 0.720590807786267} |\n",
    "\n",
    "*Execution time* <br /> \n",
    "CPU times: user 4h 47min 57s, sys: 1h 35min 35s, total: 6h 23min 33s\n",
    "Wall time: 2h 36min 18s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####remove the comment and run the code for experiments with hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = {'train': tokens_train, 'test': tokens_test, 'bo': tokens_bo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for GRU set unit='GRU'\n",
    "#%time eh.run_hiddim_options(hidden_dims, start_index, end_index, bert_vocab, bert_embeddings, colors, tokens, unit='GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Baseline model using BERT pretrained embeddings and vocab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineLSTMDescriber(\n",
    "    bert_vocab,\n",
    "    embedding=bert_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLNet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tokens_train, tokens_test, tokens_bo = \\\n",
    "    eh.create_tokens_sets(xlnet_tokenizer, texts_train, texts_test, texts_test_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time xlnet_embeddings, xlnet_vocab = mu.extract_input_embeddings(texts_train, xlnet_model, xlnet_tokenizer, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiment with different hidden_dim size***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - XLNet LSTM - static embeddings + ResNet+Fourier |\n",
    "| ------- |\n",
    "| Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 51.43806719779968 <br /> train 50 - {'listener_accuracy': 0.40028938633075156, 'corpus_bleu': 0.11601226111917491} <br /> bake-off 50 - {'listener_accuracy': 0.34859675036927623, 'corpus_bleu': 0.12250562016041742} |\n",
    "| Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 50.56151986122131 <br /> train 100 - {'listener_accuracy': 0.38420291088603287, 'corpus_bleu': 0.10000000000000002} <br /> bake-off 100 - {'listener_accuracy': 0.38010832102412606, 'corpus_bleu': 0.10000000000000002} |\n",
    "| Stopping after epoch 65. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 44.73309278488159 <br /> train 150 - {'listener_accuracy': 0.5334922121031577, 'corpus_bleu': 0.4307617849191753} <br /> bake-off 150 - {'listener_accuracy': 0.6011816838995568, 'corpus_bleu': 0.3972355769230769} |\n",
    "| Stopping after epoch 81. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 41.55567979812622 <br /> train 250 - {'listener_accuracy': 0.5929015235339178, 'corpus_bleu': 0.5084326142252633} <br /> bake-off 250 - {'listener_accuracy': 0.6932545544066963, 'corpus_bleu': 0.6762724153392196} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - XLNet GRU - static embeddings + ResNet+Fourier |\n",
    "| ------- |\n",
    "| Stopping after epoch 22. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 49.95226716995239 <br /> train 50 - {'listener_accuracy': 0.4078644991063069, 'corpus_bleu': 0.22546245072544133} <br /> bake-off 50 - {'listener_accuracy': 0.4017725258493353, 'corpus_bleu': 0.367694263699723} |\n",
    "| Stopping after epoch 32. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 47.21669912338257 <br /> train 100 - {'listener_accuracy': 0.4464209719976168, 'corpus_bleu': 0.5122018513333958} <br /> bake-off 100 - {'listener_accuracy': 0.4938453963564746, 'corpus_bleu': 0.688742937744571} |\n",
    "| Stopping after epoch 35. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 46.30550456047058 <br /> train 150 - {'listener_accuracy': 0.5110222146565665, 'corpus_bleu': 0.4031163071177077} <br /> bake-off 150 - {'listener_accuracy': 0.5558838010832102, 'corpus_bleu': 0.40430663221360896} |\n",
    "| Stopping after epoch 42. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 44.303759813308716 <br /> train 250 - {'listener_accuracy': 0.5473657332538939, 'corpus_bleu': 0.5113511314807752} <br /> bake-off 250 - {'listener_accuracy': 0.6272772033481043, 'corpus_bleu': 0.6787631418303108} |\n",
    "\n",
    "*Execetion time* <br /> \n",
    "CPU times: user 2h 33min 14s, sys: 49min 24s, total: 3h 22min 39s\n",
    "Wall time: 1h 23min 39s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###remove the comment and run the code for experiments with hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = {'train': tokens_train, 'test': tokens_test, 'bo': tokens_bo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###for GRU set unit='GRU'\n",
    "#%time eh.run_hiddim_options(hidden_dims, start_index, end_index, xlnet_vocab, xlnet_embeddings, colors, tokens, unit='GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Baseline model using XLNet pretrained embeddings and vocab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xlnet_lstm = BaselineLSTMDescriber(\n",
    "    vocab=xlnet_vocab,\n",
    "    embedding=xlnet_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model_xlnet_lstm.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_xlnet_lstm.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_xlnet_lstm.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xlnet_gru = BaselineDescriber(\n",
    "    vocab=xlnet_vocab,\n",
    "    embedding=xlnet_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model_xlnet_gru.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_xlnet_gru.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_xlnet_gru.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tokens_train, tokens_test, tokens_bo = \\\n",
    "    eh.create_tokens_sets(roberta_tokenizer, texts_train, texts_test, texts_test_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time roberta_embeddings, roberta_vocab = mu.extract_input_embeddings(texts_train, roberta_model, roberta_tokenizer, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiment with different hidden_dim size***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - RoBERTa GRU - static embeddings + ResNet+Fourier|\n",
    "| ------- |\n",
    "| Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 50.86355710029602 <br /> train 50 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.15} <br /> bake-off 50 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.15} |\n",
    "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 52.07556104660034 <br /> train 100 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} <br /> bake-off 100 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "| Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 50.25857353210449 <br /> train 150 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} <br /> bake-off 150 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "| Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 50.29149055480957 <br /> train 250 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} <br /> bake-off 250 - {'listener_accuracy': 1.0, 'corpus_bleu': 0.2} |\n",
    "\n",
    "*Execution time* <br /> \n",
    "CPU times: user 1h 16min 18s, sys: 21min 54s, total: 1h 38min 12s\n",
    "Wall time: 41min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###remove the comment and run the code for experiments with hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {'train': tokens_train, 'test': tokens_test, 'bo': tokens_bo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###for GRU set unit='GRU'\n",
    "%time eh.run_hiddim_options(hidden_dims, start_index, end_index, roberta_vocab, roberta_embeddings, colors, tokens, unit='GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Baseline model using RoBERTa pretrained embeddings and vocab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineLSTMDescriber(\n",
    "    roberta_vocab,\n",
    "    embedding=roberta_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELECTRA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "electra_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tokens_train, tokens_test, tokens_bo = \\\n",
    "    eh.create_tokens_sets(electra_tokenizer, texts_train, texts_test, texts_test_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time electra_embeddings, electra_vocab = mu.extract_input_embeddings(texts_train, electra_model, electra_tokenizer, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Experiment with different hidden_dim size***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - ELECTRA LSTM - static embeddings + ResNet+Fourier|\n",
    "| ------- |\n",
    "| Stopping after epoch 23. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 47.63471579551697 <br /> train 50 - {'listener_accuracy': 0.3909268873946719, 'corpus_bleu': 0.15} <br /> bake-off 50 - {'listener_accuracy': 0.3845396356474643, 'corpus_bleu': 0.15} |\n",
    "| Stopping after epoch 21. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 49.45027256011963 <br /> train 100 - {'listener_accuracy': 0.42471699719125033, 'corpus_bleu': 0.5404861636039842} <br /> bake-off 100 - {'listener_accuracy': 0.4244214672575086, 'corpus_bleu': 0.6658470617162527} |\n",
    "| Stopping after epoch 63. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 41.79938507080078 <br /> train 150 - {'listener_accuracy': 0.5634522086986127, 'corpus_bleu': 0.5305960626612526} <br /> bake-off 150 - {'listener_accuracy': 0.6149679960610537, 'corpus_bleu': 0.6977797477288923} |\n",
    "| Stopping after epoch 59. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 44.45513558387756 <br /> train 250 - {'listener_accuracy': 0.5720486849944676, 'corpus_bleu': 0.5589953211796204} <br /> bake-off 250 - {'listener_accuracy': 0.6297390448055146, 'corpus_bleu': 0.7396116726551871} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Results - ELECTRA GRU - static embeddings + ResNet+Fourier|\n",
    "| ------- |\n",
    "| Stopping after epoch 39. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 47.41162323951721 <br /> train 50 - {'listener_accuracy': 0.4632734700825602, 'corpus_bleu': 0.4777896222522073} <br /> bake-off 50 - {'listener_accuracy': 0.4938453963564746, 'corpus_bleu': 0.657231763491947} |\n",
    "| Stopping after epoch 34. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 46.33916139602661 <br /> train 100 - {'listener_accuracy': 0.4330581326070304, 'corpus_bleu': 0.5023199247333534} <br /> bake-off 100 - {'listener_accuracy': 0.4401772525849335, 'corpus_bleu': 0.6706403921940264} |\n",
    "| Stopping after epoch 37. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 43.32993298768997 <br /> train 150 - {'listener_accuracy': 0.5265128947144437, 'corpus_bleu': 0.5373655274110541} <br /> bake-off 150 - {'listener_accuracy': 0.5824716888232397, 'corpus_bleu': 0.7040877364082542} |\n",
    "| Stopping after epoch 65. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 44.20422172546387 <br /> train 250 - {'listener_accuracy': 0.5704315260873266, 'corpus_bleu': 0.5305960626612526} <br /> bake-off 250 - {'listener_accuracy': 0.6366322008862629, 'corpus_bleu': 0.6977797477288923} |\n",
    "\n",
    "*Execution time* <br /> \n",
    "CPU times: user 2h 54min 38s, sys: 54min 51s, total: 3h 49min 29s\n",
    "Wall time: 1h 33min 24s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###remove the comment and run the code for experiments with hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = {'train': tokens_train, 'test': tokens_test, 'bo': tokens_bo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###for GRU set unit='GRU'\n",
    "#%time eh.run_hiddim_options(hidden_dims, start_index, end_index, electra_vocab, electra_embeddings, colors, tokens, unit='GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Baseline model using ELECTRA pretrained embeddings and vocab***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/experiments/xlnet_gru_resnet_vscores_2.txt\", \"w\") as f:\n",
    "    f.write(str(model_xlnet_gru.validation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = BaselineLSTMDescriber(\n",
    "    vocab=electra_vocab,\n",
    "    embedding=electra_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model_lstm.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_lstm.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_lstm.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = BaselineDescriber(\n",
    "    vocab=electra_vocab,\n",
    "    embedding=electra_embeddings,\n",
    "    early_stopping=True,\n",
    "    hidden_dim=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = model_gru.fit(colors_train, tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_gru.evaluate(colors_test, tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on bake-off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_gru.evaluate(colors_bo, tokens_bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
