{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__authors__ = \"Anton Gochev, Jaro Habr, Yan Jiang, Samuel Kahn\"\n",
    "__version__ = \"XCS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colours with contextual embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the classes and helpers from the [model.py](experiment/model.py) library. Here we experiment with different combinations of contextual embeddings aiming to determine which will have a better performance than the basemodel or the static embeddings used in [colours_with_static_embeddings_with_convolutional_image_embeddings.ipynb](colours_with_static_embeddings_with_convolutional_image_embeddings).\n",
    "\n",
    "## WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.colors import ColorsCorpusReader\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.torch_color_describer import (\n",
    "    ContextualColorDescriber,\n",
    "    create_example_dataset\n",
    ")\n",
    "\n",
    "from utils.utils import START_SYMBOL, END_SYMBOL, UNK_SYMBOL\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetConfig, XLNetModel,\n",
    "    XLNetTokenizer, XLNetForSequenceClassification,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,\n",
    "    EncoderDecoderModel\n",
    ")\n",
    "import utils.model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exploration of the dataset counts the examples for different classes and plots the words distribition in order to see any data imbalance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered corpus is the full dataset used in assignment 4. The following code looks at the composition of the dataset, the number of example in each condition as well as the word count used in the color descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the datasets (training and bake-off) in more details refer to [colors_in_context.ipynb](colors_in_context.ipynb). The notebook shows the distribution of the colours examples among the different splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bake-Off Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code analyses the bake-off dataset. We will look at the number of examples for each of the conditions as well as the word count used to described the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAKE_OFF_COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"cs224u-colors-bakeoff-data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_corpus = ColorsCorpusReader(\n",
    "    BAKE_OFF_COLORS_SRC_FILENAME,\n",
    "    word_count=None,\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_off_examples = list(bake_off_corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2031"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bake_off_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline-System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline system is based on assignment 4 and is enhanced with new classes that allow using different contextual embedding extrsactors for easier experiments and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from baseline.model import (\n",
    "#     BaselineTokenizer, \n",
    "    BaselineColorEncoder#, \n",
    "#     BaselineDecoder,\n",
    "#     BaselineEmbedding, BaselineDescriber, GloVeEmbedding\n",
    ")\n",
    "\n",
    "from experiment.model import (\n",
    "    TransformerEmbeddingDecoder, \n",
    "    TransformerEmbeddingDescriber,\n",
    "    EmbeddingExtractorType,\n",
    "    EmbeddingExtractor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_encoder = BaselineColorEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full dataset used for training and expeiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(tokenizer):\n",
    "    rawcols, texts = zip(*[[ex.colors, ex.contents] for ex in examples])\n",
    "    \n",
    "    raw_colors_train, raw_colors_test, texts_train, texts_test = \\\n",
    "        train_test_split(rawcols, texts)\n",
    "    \n",
    "    raw_colors_train = raw_colors_train\n",
    "    texts_train = texts_train\n",
    "\n",
    "    tokens_train = [\n",
    "        mu.tokenize_colour_description(text, tokenizer) for text in texts_train\n",
    "    ]\n",
    "    colors_train = [\n",
    "        color_encoder.encode_color_context(colors) for colors in raw_colors_train\n",
    "    ]\n",
    "\n",
    "    return colors_train, tokens_train, raw_colors_test, texts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bakeoff_data():    \n",
    "    return zip(*[[ex.colors, ex.contents] for ex in bake_off_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the experiments:\n",
    "\n",
    "| Model | Hidden Layer | Protocol | Training Results | Bake-off Results |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| BERT 'bert-base-cased' | Layer 12 | Stopping after epoch 13. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.030726432800293 CPU times: user 1h 43min 56s, sys: 54min 44s, total: 2h 38min 40s Wall time: 1h 22min 48s | {'listener_accuracy': 0.2905405405405405, 'corpus_bleu': 0.07466216216216218} | {'listener_accuracy': 0.32348596750369274, 'corpus_bleu': 0.050147710487444604} |\n",
    "| BERT 'bert-base-cased' | Positional | Stopping after epoch 27. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 5.257309436798096 CPU times: user 1h 23min 10s, sys: 10min 23s, total: 1h 33min 33s Wall time: 58min 54s | {'listener_accuracy': 0.32432432432432434, 'corpus_bleu': 0.2281656643331077} | {'listener_accuracy': 0.3559822747415066, 'corpus_bleu': 0.39051130299796255} |\n",
    "| BERT 'bert-base-cased' fixed padding and baseline special symbols | Layer 12 | Stopping after epoch 14. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.11735725402832 CPU times: user 1h 44min 47s, sys: 54min 54s, total: 2h 39min 42s Wall time: 1h 21min 23s | {'listener_accuracy': 0.36486486486486486, 'corpus_bleu': 0.035602020040005664} | {'listener_accuracy': 0.3658296405711472, 'corpus_bleu': 0.41658000242602683} |\n",
    "| BERT 'bert-base-cased' fixed padding and BERT special symbols | Layer 12 | Stopping after epoch 15. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 5.931732177734375 CPU times: user 1h 53min 23s, sys: 59min 28s, total: 2h 52min 52s Wall time: 1h 29min 26s | {'listener_accuracy': 0.34459459459459457, 'corpus_bleu': 0.05016891891891893} | {'listener_accuracy': 0.3293943870014771, 'corpus_bleu': 0.050147710487444604} | \n",
    "| XLNet 'xlnet-base-cased' |  |  |  |  |\n",
    "| RoBERTa 'roberta-base' |  |  |  |  |\n",
    "| ELECTRA 'google/electra-small-discriminator' |  |  |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial experiments show that using just contextual or positional embeddings is certainly not improving the performance. It seems that those are very high-level and we are missing on some of the low level context static embeddings provide us with. Therefore, next steps are to implement and text embeddings extractors that make use of the static embeddings. \n",
    "- Do not throw away the static embeddings as they have good performance\n",
    "- Combine the static embeddings with the [CLS] output to see what the result is (he had good experience with such approach)\n",
    "- Combine the static embeddings with the output of the model (contextual embeddings/last hidden state) to see if there is any improvement\n",
    "\n",
    "In additoin, we will try with different model complexity (increase the hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trained_model, tokenizer, color_seqs_test, texts_test):\n",
    "    tok_seqs = [mu.tokenize_colour_description(text, tokenizer) for text in texts_test]\n",
    "    col_seqs = [color_encoder.encode_color_context(colors) for colors in color_seqs_test]\n",
    "\n",
    "    return trained_model.evaluate(col_seqs, tok_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_raw_colors_test, b_texts_test = create_bakeoff_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many(colors_train, tokens_train, extractors=None):\n",
    "    assert extractors != None and type(extractors) is list, \\\n",
    "            \"Expected a list of extractors but got something else\"\n",
    "    \n",
    "    models = []\n",
    "    for extractor in extractors:\n",
    "        model = TransformerEmbeddingDescriber(\n",
    "            vocab=bert_vocab,\n",
    "            embedding=bert_embeddings,\n",
    "            model=bert_model,\n",
    "            tokenizer=bert_tokenizer,\n",
    "            embed_extractor=embedding_extractor,\n",
    "            early_stopping=True)\n",
    "        %time model.fit(colors_train, tokens_train)\n",
    "        models.append(model)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_many(models, tokenizer, raw_colors_test, texts_test):\n",
    "    assert models != None and type(models) is list, \\\n",
    "        \"Expected a list of models but got something else\"\n",
    "    \n",
    "    results = []\n",
    "    for model in models:\n",
    "        %time results.append(evaluate(model, tokenizer, raw_colors_test, texts_test))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_extractors = [\n",
    "    EmbeddingExtractor(EmbeddingExtractorType.STATIC),\n",
    "    EmbeddingExtractor(EmbeddingExtractorType.POSITIONAL),\n",
    "    EmbeddingExtractor(EmbeddingExtractorType.LAYER12)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.05 s, sys: 111 ms, total: 8.16 s\n",
      "Wall time: 8.18 s\n"
     ]
    }
   ],
   "source": [
    "%time  colors_train, tokens_train, raw_colors_test, texts_test = create_data(bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 5.9898362159729"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 267 ms, total: 1.32 s\n",
      "Wall time: 1.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.020166873931885"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 224 ms, total: 1.35 s\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.24141263961792"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 233 ms, total: 1.41 s\n",
      "Wall time: 890 ms\n"
     ]
    }
   ],
   "source": [
    "models = train_many(colors_train[:5], tokens_train[:5], extractors=embedding_extractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.9 ms, sys: 9.52 ms, total: 72.5 ms\n",
      "Wall time: 67 ms\n",
      "CPU times: user 50.2 ms, sys: 1.99 ms, total: 52.2 ms\n",
      "Wall time: 50.5 ms\n",
      "CPU times: user 50 ms, sys: 2.14 ms, total: 52.1 ms\n",
      "Wall time: 50.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.2, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, bert_tokenizer, raw_colors_test[:5], texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate with bake-off data the model hasn't seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 ms, sys: 3.86 ms, total: 52.6 ms\n",
      "Wall time: 51.3 ms\n",
      "CPU times: user 48.9 ms, sys: 2.68 ms, total: 51.6 ms\n",
      "Wall time: 49.6 ms\n",
      "CPU times: user 49 ms, sys: 3.68 ms, total: 52.7 ms\n",
      "Wall time: 49.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.2, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, bert_tokenizer, b_raw_colors_test[:5], b_texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLNet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.85 s, sys: 993 ms, total: 8.84 s\n",
      "Wall time: 9.16 s\n"
     ]
    }
   ],
   "source": [
    "%time  colors_train, tokens_train, raw_colors_test, texts_test = create_data(xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 21. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.09463357925415"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 1.14 s, total: 2.75 s\n",
      "Wall time: 2.23 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.791963577270508"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 178 ms, total: 1.24 s\n",
      "Wall time: 756 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.765586853027344"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 288 ms, total: 1.47 s\n",
      "Wall time: 856 ms\n"
     ]
    }
   ],
   "source": [
    "models = train_many(colors_train[:5], tokens_train[:5], extractors=embedding_extractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 ms, sys: 7.43 ms, total: 64.5 ms\n",
      "Wall time: 67.3 ms\n",
      "CPU times: user 51.7 ms, sys: 3.71 ms, total: 55.5 ms\n",
      "Wall time: 55.1 ms\n",
      "CPU times: user 49.5 ms, sys: 2.32 ms, total: 51.8 ms\n",
      "Wall time: 49.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.6, 'corpus_bleu': 0.06},\n",
       " {'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, xlnet_tokenizer, raw_colors_test[:5], texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate with bake-off data the model hasn't seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.8 ms, sys: 3.01 ms, total: 59.8 ms\n",
      "Wall time: 57.5 ms\n",
      "CPU times: user 47.3 ms, sys: 3.31 ms, total: 50.6 ms\n",
      "Wall time: 47.8 ms\n",
      "CPU times: user 47.8 ms, sys: 2.79 ms, total: 50.6 ms\n",
      "Wall time: 47.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.2, 'corpus_bleu': 0.07058823529411766},\n",
       " {'listener_accuracy': 0.6, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.0, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, xlnet_tokenizer, b_raw_colors_test[:5], b_texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.38 s, sys: 235 ms, total: 8.61 s\n",
      "Wall time: 8.66 s\n"
     ]
    }
   ],
   "source": [
    "%time  colors_train, tokens_train, raw_colors_test, texts_test = create_data(roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.189422607421875"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 201 ms, total: 1.35 s\n",
      "Wall time: 792 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.499911785125732"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 206 ms, total: 1.35 s\n",
      "Wall time: 800 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.431423664093018"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 199 ms, total: 1.34 s\n",
      "Wall time: 778 ms\n"
     ]
    }
   ],
   "source": [
    "models = train_many(colors_train[:5], tokens_train[:5], extractors=embedding_extractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.6 ms, sys: 7.23 ms, total: 64.8 ms\n",
      "Wall time: 62.5 ms\n",
      "CPU times: user 50 ms, sys: 1.85 ms, total: 51.8 ms\n",
      "Wall time: 50 ms\n",
      "CPU times: user 50.1 ms, sys: 2.45 ms, total: 52.5 ms\n",
      "Wall time: 50.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, roberta_tokenizer, raw_colors_test[:5], texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate with bake-off data the model hasn't seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.7 ms, sys: 3.43 ms, total: 63.1 ms\n",
      "Wall time: 60.5 ms\n",
      "CPU times: user 56.1 ms, sys: 2.45 ms, total: 58.5 ms\n",
      "Wall time: 57 ms\n",
      "CPU times: user 48.5 ms, sys: 2.14 ms, total: 50.6 ms\n",
      "Wall time: 49 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, roberta_tokenizer, b_raw_colors_test[:5], b_texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELECTRA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "electra_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.32 s, sys: 111 ms, total: 9.43 s\n",
      "Wall time: 9.45 s\n"
     ]
    }
   ],
   "source": [
    "%time  colors_train, tokens_train, raw_colors_test, texts_test = create_data(electra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings, bert_vocab = mu.extract_input_embeddings(texts_test, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.825011253356934"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 660 ms, sys: 144 ms, total: 804 ms\n",
      "Wall time: 541 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 12. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.785768032073975"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 686 ms, sys: 153 ms, total: 839 ms\n",
      "Wall time: 575 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 20. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 6.495962619781494"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 981 ms, sys: 361 ms, total: 1.34 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "models = train_many(colors_train[:5], tokens_train[:5], extractors=embedding_extractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 ms, sys: 6.83 ms, total: 61.1 ms\n",
      "Wall time: 57.9 ms\n",
      "CPU times: user 47 ms, sys: 2.19 ms, total: 49.2 ms\n",
      "Wall time: 47.1 ms\n",
      "CPU times: user 47.7 ms, sys: 2.53 ms, total: 50.2 ms\n",
      "Wall time: 47.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.0, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.4, 'corpus_bleu': 0.1076923076923077}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, electra_tokenizer, raw_colors_test[:5], texts_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate with bake-off data the model hasn't seen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.1 ms, sys: 2.82 ms, total: 52.9 ms\n",
      "Wall time: 50.8 ms\n",
      "CPU times: user 50.6 ms, sys: 3.32 ms, total: 54 ms\n",
      "Wall time: 50.8 ms\n",
      "CPU times: user 46.8 ms, sys: 2.95 ms, total: 49.8 ms\n",
      "Wall time: 47 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'listener_accuracy': 0.4, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.2, 'corpus_bleu': 0.05000000000000001},\n",
       " {'listener_accuracy': 0.2, 'corpus_bleu': 0.05000000000000001}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_many(models, electra_tokenizer, b_raw_colors_test[:5], b_texts_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
