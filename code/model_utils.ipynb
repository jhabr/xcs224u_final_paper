{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colors import ColorsCorpusReader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetTokenizer, XLNetModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,    \n",
    ")\n",
    "\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_SRC_FILENAME = os.path.join(\n",
    "    \"data\", \"colors\", \"filteredCorpus.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ColorsCorpusReader(\n",
    "    COLORS_SRC_FILENAME,\n",
    "    word_count=None, #2\n",
    "    normalize_colors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = list(corpus.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_examples = [example for example in examples if example.condition == \"close\"]\n",
    "split_examples = [example for example in examples if example.condition == \"split\"]\n",
    "far_examples = [example for example in examples if example.condition == \"far\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "close: 15519\n",
      "split: 15693\n",
      "far: 15782\n"
     ]
    }
   ],
   "source": [
    "print(f\"close: {len(close_examples)}\")\n",
    "print(f\"split: {len(split_examples)}\")\n",
    "print(f\"far: {len(far_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rawcols, dev_texts = zip(*[[ex.colors, ex.contents] for ex in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_colours = [\n",
    "    'brown. not the yellow one or classic brown one, the weirder one', \n",
    "    'brown. not the yellow one or classic brown one',\n",
    "    'some other brown. that one'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert model embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 3058,  119, 1136, 1103, 3431, 1141, 1137, 5263, 3058, 1141,  117,\n",
       "         1103, 6994, 1200, 1141,  102]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(bert_tokenizer.encode(test_colours, add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'brown',\n",
       " '.',\n",
       " 'not',\n",
       " 'the',\n",
       " 'yellow',\n",
       " 'one',\n",
       " 'or',\n",
       " 'classic',\n",
       " 'brown',\n",
       " 'one',\n",
       " ',',\n",
       " 'the',\n",
       " 'weird',\n",
       " '##er',\n",
       " 'one',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btokens = bert_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "btokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'brown': tensor(-0.0584, grad_fn=<SelectBackward>),\n",
       "  'not': tensor(-0.0163, grad_fn=<SelectBackward>),\n",
       "  'the': tensor(0.0056, grad_fn=<SelectBackward>),\n",
       "  'yellow': tensor(-0.0260, grad_fn=<SelectBackward>),\n",
       "  'one': tensor(0.0207, grad_fn=<SelectBackward>),\n",
       "  'or': tensor(-0.0833, grad_fn=<SelectBackward>),\n",
       "  'classic': tensor(-0.0158, grad_fn=<SelectBackward>),\n",
       "  'weird': tensor(0.0265, grad_fn=<SelectBackward>),\n",
       "  'er': tensor(-0.0054, grad_fn=<SelectBackward>)},\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'weird', 'er'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_input_embeddings(test_colours, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['brown_0', tensor(-1.5282, grad_fn=<SelectBackward>)],\n",
       "  ['not_1', tensor(-0.2150, grad_fn=<SelectBackward>)],\n",
       "  ['the_2', tensor(0.1125, grad_fn=<SelectBackward>)],\n",
       "  ['yellow_3', tensor(-0.2057, grad_fn=<SelectBackward>)],\n",
       "  ['one_4', tensor(0.6377, grad_fn=<SelectBackward>)],\n",
       "  ['or_5', tensor(-1.7041, grad_fn=<SelectBackward>)],\n",
       "  ['classic_6', tensor(-0.0015, grad_fn=<SelectBackward>)],\n",
       "  ['brown_7', tensor(1.2130, grad_fn=<SelectBackward>)],\n",
       "  ['one_8', tensor(0.6641, grad_fn=<SelectBackward>)],\n",
       "  ['the_9', tensor(0.6327, grad_fn=<SelectBackward>)],\n",
       "  ['weird_10', tensor(0.7618, grad_fn=<SelectBackward>)],\n",
       "  ['er_11', tensor(0.6339, grad_fn=<SelectBackward>)]],\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'weird', 'er'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_contextual_embeddings(test_colours, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 55.6 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "bert_embeddings, bert_vocab = mu.extract_input_embeddings(dev_texts, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract contextual embeddings (pre-trained embedding + position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 4s, sys: 1min 47s, total: 42min 51s\n",
      "Wall time: 42min 30s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "bert_contextual_embeddings, bert_contextual_vocab = mu.extract_contextual_embeddings(dev_texts, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XLNet model embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3442,    9,   50,   18, 3493,   65,   49, 3523, 3442,   65,   19,   18,\n",
       "         8189,  118,   65,    4,    3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(xlnet_tokenizer.encode(test_colours, add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁brown',\n",
       " '.',\n",
       " '▁not',\n",
       " '▁the',\n",
       " '▁yellow',\n",
       " '▁one',\n",
       " '▁or',\n",
       " '▁classic',\n",
       " '▁brown',\n",
       " '▁one',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁weird',\n",
       " 'er',\n",
       " '▁one',\n",
       " '<sep>',\n",
       " '<cls>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = xlnet_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'▁brown': tensor(0.0211, grad_fn=<SelectBackward>),\n",
       "  '▁not': tensor(-0.0018, grad_fn=<SelectBackward>),\n",
       "  '▁the': tensor(0.0811, grad_fn=<SelectBackward>),\n",
       "  '▁yellow': tensor(-0.1191, grad_fn=<SelectBackward>),\n",
       "  '▁one': tensor(0.0029, grad_fn=<SelectBackward>),\n",
       "  '▁or': tensor(-0.0841, grad_fn=<SelectBackward>),\n",
       "  '▁classic': tensor(-0.0960, grad_fn=<SelectBackward>),\n",
       "  '▁weird': tensor(0.0480, grad_fn=<SelectBackward>),\n",
       "  'er': tensor(-0.0640, grad_fn=<SelectBackward>)},\n",
       " ['▁brown',\n",
       "  '▁not',\n",
       "  '▁the',\n",
       "  '▁yellow',\n",
       "  '▁one',\n",
       "  '▁or',\n",
       "  '▁classic',\n",
       "  '▁weird',\n",
       "  'er'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_input_embeddings(test_colours, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['▁brown_0', tensor(0.0211, grad_fn=<SelectBackward>)],\n",
       "  ['▁not_1', tensor(-0.0018, grad_fn=<SelectBackward>)],\n",
       "  ['▁the_2', tensor(0.0811, grad_fn=<SelectBackward>)],\n",
       "  ['▁yellow_3', tensor(-0.1191, grad_fn=<SelectBackward>)],\n",
       "  ['▁one_4', tensor(0.0029, grad_fn=<SelectBackward>)],\n",
       "  ['▁or_5', tensor(-0.0841, grad_fn=<SelectBackward>)],\n",
       "  ['▁classic_6', tensor(-0.0960, grad_fn=<SelectBackward>)],\n",
       "  ['▁brown_7', tensor(-0.1039, grad_fn=<SelectBackward>)],\n",
       "  ['▁one_8', tensor(-0.0244, grad_fn=<SelectBackward>)],\n",
       "  ['▁the_9', tensor(0.0836, grad_fn=<SelectBackward>)],\n",
       "  ['▁weird_10', tensor(0.0480, grad_fn=<SelectBackward>)],\n",
       "  ['er_11', tensor(-0.0640, grad_fn=<SelectBackward>)],\n",
       "  ['▁one_12', tensor(-0.0657, grad_fn=<SelectBackward>)]],\n",
       " ['▁brown',\n",
       "  '▁not',\n",
       "  '▁the',\n",
       "  '▁yellow',\n",
       "  '▁one',\n",
       "  '▁or',\n",
       "  '▁classic',\n",
       "  '▁weird',\n",
       "  'er'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_contextual_embeddings(test_colours, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.78 s, sys: 82.6 ms, total: 9.87 s\n",
      "Wall time: 9.88 s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "xlnet_embeddings, xlnet_vocab = mu.extract_input_embeddings(dev_texts, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract contextual embeddings (pre-trained embedding + position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 5s, sys: 2min, total: 50min 5s\n",
      "Wall time: 49min 44s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "xlnet_contextual_embeddings, xlnet_contextual_vocab = mu.extract_contextual_embeddings(dev_texts, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa model embeddings extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 31876,     4,    45,     5,  5718,    65,    50,  4187,  6219,\n",
       "            65,     6,     5,    52,   853,  3624,    65,     2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(roberta_tokenizer.encode(test_colours, add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'brown',\n",
       " '.',\n",
       " 'Ġnot',\n",
       " 'Ġthe',\n",
       " 'Ġyellow',\n",
       " 'Ġone',\n",
       " 'Ġor',\n",
       " 'Ġclassic',\n",
       " 'Ġbrown',\n",
       " 'Ġone',\n",
       " ',',\n",
       " 'Ġthe',\n",
       " 'Ġwe',\n",
       " 'ir',\n",
       " 'der',\n",
       " 'Ġone',\n",
       " '</s>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtest = roberta_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "rtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'brown': tensor(0.2496, grad_fn=<SelectBackward>),\n",
       "  'not': tensor(-0.1255, grad_fn=<SelectBackward>),\n",
       "  'the': tensor(0.1127, grad_fn=<SelectBackward>),\n",
       "  'yellow': tensor(0.0967, grad_fn=<SelectBackward>),\n",
       "  'one': tensor(-0.0260, grad_fn=<SelectBackward>),\n",
       "  'or': tensor(0.1552, grad_fn=<SelectBackward>),\n",
       "  'classic': tensor(-0.2581, grad_fn=<SelectBackward>),\n",
       "  'we': tensor(-0.0199, grad_fn=<SelectBackward>),\n",
       "  'ir': tensor(-0.0872, grad_fn=<SelectBackward>),\n",
       "  'der': tensor(0.0023, grad_fn=<SelectBackward>)},\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'we', 'ir', 'der'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_input_embeddings(test_colours, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['brown_0', tensor(0.4642, grad_fn=<SelectBackward>)],\n",
       "  ['not_1', tensor(-0.2442, grad_fn=<SelectBackward>)],\n",
       "  ['the_2', tensor(0.4069, grad_fn=<SelectBackward>)],\n",
       "  ['yellow_3', tensor(0.2805, grad_fn=<SelectBackward>)],\n",
       "  ['one_4', tensor(0.2763, grad_fn=<SelectBackward>)],\n",
       "  ['or_5', tensor(0.4153, grad_fn=<SelectBackward>)],\n",
       "  ['classic_6', tensor(-0.3730, grad_fn=<SelectBackward>)],\n",
       "  ['brown_7', tensor(0.0910, grad_fn=<SelectBackward>)],\n",
       "  ['one_8', tensor(-0.5839, grad_fn=<SelectBackward>)],\n",
       "  ['the_9', tensor(0.0514, grad_fn=<SelectBackward>)],\n",
       "  ['we_10', tensor(-0.0807, grad_fn=<SelectBackward>)],\n",
       "  ['ir_11', tensor(-0.1418, grad_fn=<SelectBackward>)],\n",
       "  ['der_12', tensor(-0.0013, grad_fn=<SelectBackward>)]],\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'we', 'ir', 'der'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_contextual_embeddings(test_colours, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 207 ms, total: 10.9 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "roberta_embeddings, roberta_vocab = mu.extract_input_embeddings(dev_texts, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract contextual embeddings (pre-trained embedding + position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 42s, sys: 2min 25s, total: 48min 7s\n",
      "Wall time: 47min 32s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "xlnet_contextual_embeddings, xlnet_contextual_vocab = mu.extract_contextual_embeddings(dev_texts, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELECTRA model embeddings extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "electra_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2829, 1012, 2025, 1996, 3756, 2028, 2030, 4438, 2829, 2028, 1010,\n",
       "         1996, 6881, 2121, 2028,  102]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(electra_tokenizer.encode(test_colours, add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'brown',\n",
       " '.',\n",
       " 'not',\n",
       " 'the',\n",
       " 'yellow',\n",
       " 'one',\n",
       " 'or',\n",
       " 'classic',\n",
       " 'brown',\n",
       " 'one',\n",
       " ',',\n",
       " 'the',\n",
       " 'weird',\n",
       " '##er',\n",
       " 'one',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtest = electra_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "rtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'brown': tensor(-0.0039, grad_fn=<SelectBackward>),\n",
       "  'not': tensor(-0.0407, grad_fn=<SelectBackward>),\n",
       "  'the': tensor(-0.1072, grad_fn=<SelectBackward>),\n",
       "  'yellow': tensor(0.0862, grad_fn=<SelectBackward>),\n",
       "  'one': tensor(-0.0352, grad_fn=<SelectBackward>),\n",
       "  'or': tensor(-0.0047, grad_fn=<SelectBackward>),\n",
       "  'classic': tensor(-0.0245, grad_fn=<SelectBackward>),\n",
       "  'weird': tensor(0.0663, grad_fn=<SelectBackward>),\n",
       "  'er': tensor(0.1498, grad_fn=<SelectBackward>)},\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'weird', 'er'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_input_embeddings(test_colours, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['brown_0', tensor(-0.0532, grad_fn=<SelectBackward>)],\n",
       "  ['not_1', tensor(-0.2128, grad_fn=<SelectBackward>)],\n",
       "  ['the_2', tensor(-0.0007, grad_fn=<SelectBackward>)],\n",
       "  ['yellow_3', tensor(0.6196, grad_fn=<SelectBackward>)],\n",
       "  ['one_4', tensor(-0.3050, grad_fn=<SelectBackward>)],\n",
       "  ['or_5', tensor(0.3348, grad_fn=<SelectBackward>)],\n",
       "  ['classic_6', tensor(-0.7161, grad_fn=<SelectBackward>)],\n",
       "  ['brown_7', tensor(0.3253, grad_fn=<SelectBackward>)],\n",
       "  ['one_8', tensor(-0.2708, grad_fn=<SelectBackward>)],\n",
       "  ['the_9', tensor(-0.7404, grad_fn=<SelectBackward>)],\n",
       "  ['weird_10', tensor(0.5968, grad_fn=<SelectBackward>)],\n",
       "  ['er_11', tensor(-0.4330, grad_fn=<SelectBackward>)]],\n",
       " ['brown', 'not', 'the', 'yellow', 'one', 'or', 'classic', 'weird', 'er'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.extract_contextual_embeddings(test_colours, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 97.3 ms, total: 12.8 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "roberta_embeddings, roberta_vocab = mu.extract_input_embeddings(dev_texts, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract contextual embeddings (pre-trained embedding + position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 43s, sys: 1min 1s, total: 13min 45s\n",
      "Wall time: 13min 7s\n"
     ]
    }
   ],
   "source": [
    "%time \\\n",
    "xlnet_contextual_embeddings, xlnet_contextual_vocab = mu.extract_contextual_embeddings(dev_texts, electra_model, electra_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
