{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__authors__ = \"Anton Gochev, Jaro Habr, Yan Jiang, Samuel Kahn\"\n",
    "__version__ = \"XCS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental notebook demonstrating the extraction of static embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel,\n",
    "    XLNetTokenizer, XLNetModel,\n",
    "    RobertaTokenizer, RobertaModel,\n",
    "    ElectraTokenizer, ElectraModel,    \n",
    ")\n",
    "\n",
    "import utils.model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_colours = [\n",
    "    'brown. not the yellow one or classic brown one, the weirder one', \n",
    "    'brown. not the yellow one or classic brown one',\n",
    "    'some other brown. that one'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert model embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 3058,  119, 1136, 1103, 3431, 1141, 1137, 5263, 3058, 1141,  117,\n",
       "        1103, 6994, 1200, 1141,  102])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(bert_tokenizer.encode(test_colours[0], add_special_tokens=True))\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'brown',\n",
       " '.',\n",
       " 'not',\n",
       " 'the',\n",
       " 'yellow',\n",
       " 'one',\n",
       " 'or',\n",
       " 'classic',\n",
       " 'brown',\n",
       " 'one',\n",
       " ',',\n",
       " 'the',\n",
       " 'weird',\n",
       " '##er',\n",
       " 'one',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btokens = bert_tokenizer.convert_ids_to_tokens(input_ids)\n",
    "btokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mu.extract_input_embeddings(test_colours, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = mu.extract_positional_embeddings(test_colours, bert_model, bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XLNet model embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(xlnet_tokenizer.encode(test_colours[0], add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁brown',\n",
       " '.',\n",
       " '▁not',\n",
       " '▁the',\n",
       " '▁yellow',\n",
       " '▁one',\n",
       " '▁or',\n",
       " '▁classic',\n",
       " '▁brown',\n",
       " '▁one',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁weird',\n",
       " 'er',\n",
       " '▁one',\n",
       " '<sep>',\n",
       " '<cls>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest = xlnet_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mu.extract_input_embeddings(test_colours, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = mu.extract_positional_embeddings(test_colours, xlnet_model, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RoBERTa model embeddings extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(roberta_tokenizer.encode(test_colours[0], add_special_tokens=True)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'brown',\n",
       " '.',\n",
       " 'Ġnot',\n",
       " 'Ġthe',\n",
       " 'Ġyellow',\n",
       " 'Ġone',\n",
       " 'Ġor',\n",
       " 'Ġclassic',\n",
       " 'Ġbrown',\n",
       " 'Ġone',\n",
       " ',',\n",
       " 'Ġthe',\n",
       " 'Ġwe',\n",
       " 'ir',\n",
       " 'der',\n",
       " 'Ġone',\n",
       " '</s>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtest = roberta_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "rtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mu.extract_input_embeddings(test_colours, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = mu.extract_positional_embeddings(test_colours, roberta_model, roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELECTRA model embeddings extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "electra_model = ElectraModel.from_pretrained('google/electra-small-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2829, 1012, 2025, 1996, 3756, 2028, 2030, 4438, 2829, 2028, 1010,\n",
       "         1996, 6881, 2121, 2028,  102]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(electra_tokenizer.encode(test_colours[0], add_special_tokens=True)).unsqueeze(0)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'brown',\n",
       " '.',\n",
       " 'not',\n",
       " 'the',\n",
       " 'yellow',\n",
       " 'one',\n",
       " 'or',\n",
       " 'classic',\n",
       " 'brown',\n",
       " 'one',\n",
       " ',',\n",
       " 'the',\n",
       " 'weird',\n",
       " '##er',\n",
       " 'one',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtest = electra_tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "rtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mu.extract_input_embeddings(test_colours, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = mu.extract_positional_embeddings(test_colours, electra_model, electra_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate token sequences based on raw colour descriptions converted into model based tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'brown',\n",
       " 'not',\n",
       " 'the',\n",
       " 'yellow',\n",
       " 'one',\n",
       " 'or',\n",
       " 'classic',\n",
       " 'brown',\n",
       " 'one',\n",
       " 'the',\n",
       " 'weird',\n",
       " 'er',\n",
       " 'one',\n",
       " '</s>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.tokenize_colour_description(test_colours[0], tokenizer=electra_tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
