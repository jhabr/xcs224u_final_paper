\section{Introduction}

In recent years, attention-based models and especially transformers have proven to be the best performing approaches in the area of natural language processing (NLP).

\par
In this paper, our core hypothesis is that transformers’ pre-trained and contextual embeddings will enhance the word representations, therefore enhancing the performance of task of color description. We also hypothesise that using a convolutional neural network (CNN) to generate color embeddings will have a positive effect on the performance.  To test the hypothesis,  we applied pre-trained and contextual word embeddings from BERT, RoBERTA, ELECTRA and XLNet models to the task, combined with a color representation produced by ResNet , and compare them to the baseline system developed in assignment 4 of the XCS224u course. We further define our core hypotheses into three parts and tested them in this work.

\par
The first hypothesis is pre-trained and contextual embeddings will perform better than pre-trained word representations like GloVe on the task.

\par
The second hypothesis is that the models in the first hypothesis can be further enhanced by replacing the original color representation with rich color representations produced by ResNet. Additionally, hyperparameters tuning could further  boost the model performance.

\par
The third hypothesis is that different combinations (addition, mean, etc.) of the transformer’s hidden layers will improve the performance of the whole system.

\par
We found that: 1) Complex color and text representations don’t necessarily perform better than the baseline model on the given task, 2) LSTM generally showed better performance than GRU as the sequence-to-sequence architecture, which is likely due to capturing the long-term dependencies of the utterances, 3) Hyperparameters (e.g, hidden dimensions) tuning also significantly enhanced model accuracy and Bleu score.

% \begin{itemize}
%   \item area of field of work
%   \item "The central hypothesis of this paper is..."
%   \item concepts, building blocks of the hypothesis
%   \item why \emph{this} hypothesis?
%   \item steps to address hypothesis
%   \item central findings of paper
% \end{itemize}