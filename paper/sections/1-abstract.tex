\begin{abstract}

\begin{itemize}
  In this work we present a new model for a grounded communication task; identifying colors  generated from descriptions. This task uses two recurrent neural network cells which act as the speaker generating utterances. We build on previous work and introduce two novel methods for embedding our recurrent neural network inputs; a convolutional encoder for colors and a transformer network for encoding utterances. We show that coupling these two encoders with a recurrent sequence-to-sequence architectures can sometimes achieve state-of-the-art results in both listener accuracy and BLEU score, but the gains are often minimal with a much greater computational profile. In addition, our paper demonstrates that using complex encoders such as transformers or convolutional neural networks on small high dimensional datasets don't clearly outperform simpler models such as a Fourier Transform or GLoVe.


% \begin{itemize}
%   \item define current proposal, situate in context
%   \item summarize core findings
%   \item identify significance of work
% \end{itemize}

\end{abstract}